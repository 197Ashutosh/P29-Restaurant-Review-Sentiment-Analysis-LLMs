{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sW4FpPGRQhmx"
   },
   "source": [
    "\n",
    "<center><font face = 'Times New Roman' size=10>Introduction to LLMs and GenAI</center></font>\n",
    "<center><font face = 'Times New Roman' size=6>Mini Project 4 - Large Langauge Models (LLMs) and Retrieval Augmented Generation (RAG)</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2yFgYjxL6vm"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49Hj1OD_kkWG"
   },
   "source": [
    "## Business Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wMcRPLJKdE6"
   },
   "source": [
    "Growing organizations generate massive amounts of reports and data critical for decision-making. For example, venture capital analysts at firms like Andreessen Horowitz must extract insights from dense documents such as HBR’s “How Apple is Organized for Innovation.” Manual review is slow and inefficient, but Semantic Search and Retrieval-Augmented Generation (RAG) can deliver quick, precise answers to targeted questions, enabling faster strategic insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYKE35BRkspB"
   },
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcksbDgdlHhA"
   },
   "source": [
    "Build a RAG application that allows business analysts to quickly extract key insights from lengthy reports, improving efficiency and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f5p5bLolH7f"
   },
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KagUxRh3lKiv"
   },
   "source": [
    "**How Apple is Organized for Innovation** - An article of 11 pages in pdf format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnwETBOE6Bz5"
   },
   "source": [
    "# Installing and Importing Necessary Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2930,
     "status": "ok",
     "timestamp": 1758531611633,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "nhHywYfjnWJp",
    "outputId": "82a3ab12-da9f-4987-c2c9-32a1af07cd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n",
      "Found existing installation: scipy 1.16.1\n",
      "Uninstalling scipy-1.16.1:\n",
      "  Successfully uninstalled scipy-1.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip uninstall -y scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6148,
     "status": "ok",
     "timestamp": 1758531652023,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "Rc7_9Kq5nZd2",
    "outputId": "9771206b-447b-4e04-c53b-cf366e2c29ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scipy==1.11.4 in /usr/local/lib/python3.12/dist-packages (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 scipy==1.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 36011,
     "status": "ok",
     "timestamp": 1758531690800,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "FkOw4HiAxX1T",
    "outputId": "880aaadc-03e0-45e6-ea6c-a16a91fa34a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting transformers==4.44.0\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (0.23.0+cu126)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (0.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.2.2) (0.34.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.0) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.0) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.0) (0.6.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.0)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.1.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->sentence-transformers==2.2.2) (8.2.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->sentence-transformers==2.2.2) (1.5.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.0) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->sentence-transformers==2.2.2) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
      "Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=6612d240a7884f6f1ec1e1327e10b81eba101681819344c578a2263e3b4e2ca7\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/3b/21/aa025e9c81a6cda4b8358756a756677b0969b4bc69be6dd5da\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.22.0\n",
      "    Uninstalling tokenizers-0.22.0:\n",
      "      Successfully uninstalled tokenizers-0.22.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.56.1\n",
      "    Uninstalling transformers-4.56.1:\n",
      "      Successfully uninstalled transformers-4.56.1\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 5.1.0\n",
      "    Uninstalling sentence-transformers-5.1.0:\n",
      "      Successfully uninstalled sentence-transformers-5.1.0\n",
      "Successfully installed sentence-transformers-2.2.2 tokenizers-0.19.1 transformers-4.44.0\n",
      "Collecting langchain==0.1.1\n",
      "  Downloading langchain-0.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (3.12.15)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.1)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (1.33)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.9 (from langchain==0.1.1)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.1)\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.1) (8.5.0)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.1) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.1)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.1)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.1) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1.9 (from langchain==0.1.1)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2,>=0.1.9->langchain==0.1.1) (4.10.0)\n",
      "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.1)\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.9->langchain==0.1.1)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.1) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.1) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.1) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.1) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.1) (3.2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain==0.1.1) (1.3.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.1)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.1-py3-none-any.whl (802 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: packaging, mypy-extensions, typing-inspect, marshmallow, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.4.27\n",
      "    Uninstalling langsmith-0.4.27:\n",
      "      Successfully uninstalled langsmith-0.4.27\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.75\n",
      "    Uninstalling langchain-core-0.3.75:\n",
      "      Successfully uninstalled langchain-core-0.3.75\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.27\n",
      "    Uninstalling langchain-0.3.27:\n",
      "      Successfully uninstalled langchain-0.3.27\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-bigquery 3.37.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.1.23 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "xarray 2025.9.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
      "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-0.1.1 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.26.1 mypy-extensions-1.1.0 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "b4c46ec95c79440d9414da7f4171bdae",
       "pip_warning": {
        "packages": [
         "packaging"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install sentence-transformers==2.2.2 transformers==4.44.0\n",
    "!pip install langchain==0.1.1 langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101018,
     "status": "ok",
     "timestamp": 1758531809353,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "SFWPPREQxZLj",
    "outputId": "f3106727-efa2-48e2-d4db-1daaf7b70ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.8 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m217.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m190.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m239.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m189.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m319.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m376.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m377.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m294.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m264.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m361.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m195.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m387.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m150.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m312.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m309.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m331.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m335.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m362.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m338.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m317.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m239.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m293.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m311.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m366.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m298.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m319.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m298.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m323.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m297.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.9/444.9 kB\u001b[0m \u001b[31m217.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m208.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m304.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m252.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m238.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m318.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m279.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m314.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m261.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m222.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m281.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m197.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m215.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m317.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m291.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m229.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m354.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m301.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m253.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m328.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m334.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m292.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m291.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m305.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m371.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m361.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m285.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m303.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.2/107.2 kB\u001b[0m \u001b[31m273.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m282.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m347.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m253.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m279.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m304.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m381.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m375.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m319.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
      "langchain-community 0.0.20 requires numpy<2,>=1, but you have numpy 2.3.3 which is incompatible.\n",
      "langchain-community 0.0.20 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "langchain-core 0.1.23 requires packaging<24.0,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "langchain-core 0.1.23 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "langchain 0.1.1 requires numpy<2,>=1, but you have numpy 2.3.3 which is incompatible.\n",
      "langchain 0.1.1 requires tenacity<9.0.0,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.3.3 which is incompatible.\n",
      "transformers 4.44.0 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.22.1 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
      "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.1.23 which is incompatible.\n",
      "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
      "google-adk 1.13.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.32.1 which is incompatible.\n",
      "bigframes 2.19.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.1 which is incompatible.\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\n",
      "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python==0.1.85 huggingface_hub tiktoken pymupdf chromadb --force-reinstall --no-cache-dir -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1758531863502,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "qQY2aklvfefO"
   },
   "outputs": [],
   "source": [
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1259,
     "status": "ok",
     "timestamp": 1758531865929,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "7f4yFqLBINGG"
   },
   "outputs": [],
   "source": [
    "import json, os   \n",
    "import tiktoken   \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter   \n",
    "from langchain_community.document_loaders import PyMuPDFLoader       \n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings \n",
    "from langchain_community.vectorstores import Chroma             \n",
    "\n",
    "from huggingface_hub import hf_hub_download   \n",
    "from llama_cpp import Llama                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_O1PGdNO2M9"
   },
   "source": [
    "# Data Preparation for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTpWESc53dL9"
   },
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1758531870949,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "ksv9hSCR4BM_"
   },
   "outputs": [],
   "source": [
    "apple_pdf_path = \"/content/drive/MyDrive/0- July-Dec 2025/5th sem Intro to LLM and GenAI/Classroom Mini Projects/Part-4/HBR_How_Apple_Is_Organized_For_Innovation-4.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11508,
     "status": "ok",
     "timestamp": 1758531883573,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "4F2hLIBnkrvB",
    "outputId": "73238b32-22ac-4348-90fc-886ce84bbcea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1752,
     "status": "ok",
     "timestamp": 1758531885337,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "jhf34I1eYNtR"
   },
   "outputs": [],
   "source": [
    "pdf_loader = PyMuPDFLoader(apple_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1758531885928,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "YChLS31TxC3-"
   },
   "outputs": [],
   "source": [
    "apple = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffj0ca3eZT4u"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9weTDzMxRRS"
   },
   "source": [
    "#### Checking the first 3 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1758531899286,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "JSOv3q2pxX4z",
    "outputId": "21d07712-396a-4356-c39d-b0b0cbd8c7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number : 1\n",
      "REPRINT R2006F\n",
      "PUBLISHED IN HBR\n",
      "NOVEMBER–DECEMBER 2020\n",
      "ARTICLE\n",
      "ORGANIZATIONAL CULTURE\n",
      "How Apple Is \n",
      "Organized  \n",
      "for Innovation\n",
      "It’s about experts leading experts. \n",
      "by Joel M. Podolny and Morten T. Hansen\n",
      "This article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\n",
      "\n",
      "Page Number : 2\n",
      "2\n",
      "Harvard Business Review\n",
      "November–December 2020\n",
      "This article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\n",
      "\n",
      "Page Number : 3\n",
      "PHOTOGRAPHER MIKAEL JANSSON\n",
      "How Apple Is \n",
      "Organized \n",
      "for Innovation\n",
      "It’s about experts \n",
      "leading experts.\n",
      "ORGANIZATIONAL \n",
      "CULTURE\n",
      "Joel M. \n",
      "Podolny\n",
      "Dean, Apple \n",
      "University\n",
      "Morten T. \n",
      "Hansen\n",
      "Faculty, Apple \n",
      "University\n",
      "AUTHORS\n",
      "FOR ARTICLE REPRINTS CALL 800-988-0886 OR 617-783-7500, OR VISIT HBR.ORG\n",
      "Harvard Business Review\n",
      "November–December 2020  3\n",
      "This article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Page Number : {i+1}\",end=\"\\n\")\n",
    "    print(apple[i].page_content,end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIe0B8Tsx6PM"
   },
   "source": [
    "Above is the sixth page of the document.  \n",
    "- It contains shapes, text, and other elements.  \n",
    "\n",
    "Let's see how the text is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1758531907393,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "QNd6kCW3wo_t",
    "outputId": "a38a482d-32a2-486a-c0ea-6d26ad3cb570"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'targets were the overriding criteria for judging investments \\nand leaders. Significantly, the bonuses of senior R&D exec-\\nutives are based on companywide performance numbers \\nrather than the costs of or revenue from particular products. \\nThus product decisions are somewhat insulated from short-\\nterm financial pressures. The finance team is not involved in \\nthe product road map meetings of engineering teams, and \\nengineering teams are not involved in pricing decisions.\\nWe don’t mean to suggest that Apple doesn’t consider \\ncosts and revenue goals when deciding which technologies \\nand features the company will pursue. It does, but in ways \\nthat differ from those employed by conventionally organized \\ncompanies. Instead of using overall cost and price targets as \\nfixed parameters within which to make design and engineer-\\ning choices, R&D leaders are expected to weigh the benefits \\nto users of those choices against cost considerations.\\nIn a functional organization, individual and team repu-\\ntations act as a control mechanism in placing bets. A case in \\npoint is the decision to introduce the dual-lens camera with \\nportrait mode in the iPhone 7 Plus in 2016. It was a big wager \\nthat the camera’s impact on users would be sufficiently great \\nto justify its significant cost.\\nOne executive told us that Paul Hubel, a senior leader \\nwho played a central role in the portrait mode effort, was \\n“out over his skis,” meaning that he and his team were taking \\na big risk: If users were unwilling to pay a premium for a \\nphone with a more costly and better camera, the team would \\nmost likely have less credibility the next time it proposed an \\nexpensive upgrade or feature. The camera turned out to be a \\ndefining feature for the iPhone 7 Plus, and its success further \\nenhanced the reputations of Hubel and his team.\\nIt’s easier to get the balance right between an attention to \\ncosts and the value added to the user experience when the \\nleaders making decisions are those with deep expertise in \\ntheir areas rather than general managers being held account-\\nable primarily for meeting numerical targets. Whereas the \\nfundamental principle of a conventional business unit struc-\\nture is to align accountability and control, the fundamental \\nprinciple of a functional organization is to align expertise and \\ndecision rights.\\nThus the link between how Apple is organized and \\nthe type of innovations it produces is clear. As Chandler \\nfamously argued, “structure follows strategy”—even though \\nApple doesn’t use the structure that he anticipated large \\nmultinationals would adopt.\\nNow let’s turn to the leadership model underlying Apple’s \\nstructure.\\nTHREE LEADERSHIP CHARACTERISTICS\\nEver since Steve Jobs implemented the functional organi-\\nzation, Apple’s managers at every level, from senior vice \\npresident on down, have been expected to possess three key \\nleadership characteristics: deep expertise that allows them \\nto meaningfully engage in all the work being done within \\ntheir individual functions; immersion in the details of those \\nfunctions; and a willingness to collaboratively debate other \\nfunctions during collective decision-making. When manag-\\ners have these attri\\xadbutes, decisions are made in a coordinated \\nfashion by the people most qualified to make them.\\nDeep expertise. Apple is not a company where general \\nmanagers oversee managers; rather, it is a company where \\nexperts lead experts. The assumption is that it’s easier to \\ntrain an expert to manage well than to train a manager to be \\nan expert. At Apple, hardware experts manage hardware, \\nsoftware experts software, and so on. (Deviations from \\nthis principle are rare.) This approach cascades down all \\nlevels of the organization through areas of ever-\\u200bincreasing \\n2019\\nDESIGN\\nOPERATIONS\\nSALES\\nHARDWARE  \\nENGINEERING\\nRETAIL\\nPEOPLE\\nSOFTWARE\\nFINANCE\\nSERVICES\\nLEGAL\\nMACHINE LEARNING & AI\\nCORPORATE COMM.\\nHARDWARE\\nSOFTWARE\\nMARKETING\\nOPERATIONS\\nSERVICES & SUPPORT\\nSALES\\nFINANCE\\nLEGAL\\nMARKETING\\nENVIRONMENT,  \\nPOLICY & SOCIAL\\nHARDWARE  \\nTECHNOLOGIES\\nMARKETING COMM.\\nCORPORATE DEV.\\nCEO\\nApple’s Functional Organization\\nIn 1997, when Steve Jobs returned to Apple, it had a conventional structure for its size and scope. It was divided into business units, each with \\nits own P&L responsibilities. After retaking the helm, Jobs put the entire company under one P&L and combined the disparate departments of \\nthe business units into one functional organization that aligns expertise with decision rights—a structure Apple retains to this day.\\nCEO\\n1998\\n6\\nHarvard Business Review\\nNovember–December 2020\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple[5].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ1Ext5eyOXp"
   },
   "source": [
    "* If we observe the text closely, the text is not extracted sequentially.  \n",
    "\n",
    "* This is a limitation, as we are missing coherent text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-wNNalNxPKT"
   },
   "source": [
    "#### Checking the number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1758530414063,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "scMnmNKtxBea",
    "outputId": "a9640616-7d6d-41ff-ff62-ffda7ee77a76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LECMxTH-zB-R"
   },
   "source": [
    "## Data Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1758531913463,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "uG0_pBmizGGt"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name='cl100k_base',\n",
    "    chunk_size=512,\n",
    "    chunk_overlap= 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1758531914817,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "w76ji7ECzLLQ"
   },
   "outputs": [],
   "source": [
    "document_chunks = pdf_loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1758531916489,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "i6TQ-mmLzR9I",
    "outputId": "81ec8764-47a1-4631-9faa-e6f045df6d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1758531917877,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "DuRoMIGNzZaJ",
    "outputId": "f117727a-18ac-4836-c0c4-49acf7fc2552"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'REPRINT R2006F\\nPUBLISHED IN HBR\\nNOVEMBER–DECEMBER 2020\\nARTICLE\\nORGANIZATIONAL CULTURE\\nHow Apple Is \\nOrganized  \\nfor Innovation\\nIt’s about experts leading experts. \\nby Joel M. Podolny and Morten T. Hansen\\nThis article is made available to you with compliments of Apple Inc for your personal use. Further posting, copying or distribution is not permitted.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1758531920305,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "Ju4gtXwiyILp",
    "outputId": "bdb454da-8f99-412b-a9a1-a0fc18768ed3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'the answer (because they don’t). This differs starkly from \\nthe way leaders question subordinates about activities in the \\nowning and teaching boxes.\\nFinally, Rosner has delegated some areas—including \\niMovie and GarageBand, in which he is not an expert—to \\npeople with the requisite capabilities. For activities in the \\ndelegating box, he assembles teams, agrees on objectives, \\nmonitors and reviews prog\\xadress, and holds the teams account-\\nable: the stuff of general management.\\nWhereas Apple’s VPs spend most of their time in the own-\\ning and learning boxes, general managers at other companies \\ntend to spend most of their time in the delegating box. Rosner \\nestimates that he spends about 40% of his time on activities \\nhe owns (including collaboration with others in a given area), \\nabout 30% on learning, about 15% on teaching, and about 15% \\non delegating. These numbers vary by manager, of course, \\ndepending on their business and the needs at a given time.\\nThe discretionary leadership model preserves the funda\\xad\\nmental principle of an effective functional organization at \\nscale—aligning expertise and decision rights. Apple can \\neffectively move into new areas when leaders like Rosner \\ntake on new responsibilities outside their original expertise, \\nand teams can grow in size when leaders teach others their \\ncraft and delegate work. We believe that Apple will continue \\nto innovate and prosper by being organized this way.\\nAPPLE’S FUNCTIONAL ORGANIZATION is rare, if not unique, \\namong very large companies. It flies in the face of prevailing \\nmanagement theory that companies should be reorganized \\ninto divisions and business units as they become large. But \\nsomething vital gets lost in a shift to business units: the \\nalignment of decision rights with expertise.\\nWhy do companies so often cling to having general man-\\nagers in charge of business units? One reason, we believe, \\nis that making the change is difficult. It entails overcoming \\ninertia, reallocating power among managers, changing an \\nindividual-\\u200boriented incentive system, and learning new ways \\nof collaborating. That is daunting when a company already \\nfaces huge external challenges. An intermediate step may be \\nto cultivate the experts-leading-experts model even within'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chunks[-2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 744,
     "status": "aborted",
     "timestamp": 1758461841448,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "9xAQYLXqyCc6"
   },
   "outputs": [],
   "source": [
    "document_chunks[-1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl_9lAlGaYdf"
   },
   "source": [
    "As expected, there are some overlaps:  \n",
    "\n",
    "- The sentence '*to cultivate the experts-leading-experts model even within*' appears in both chunks.  \n",
    "- If we increase the `chunk_overlap`, the overlapping length of the sentence will also increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvHVejcWz0Bl"
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name='thenlper/gte-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1758531303271,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "dvc-CTtCz4kJ",
    "outputId": "d8cb39e8-c340-493e-e923-af9a486ce8a0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-603487625.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedding_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_1 = embedding_model.embed_query(document_chunks[0].page_content)\n",
    "embedding_2 = embedding_model.embed_query(document_chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "error",
     "timestamp": 1758461842022,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "W0qy6xOZ0UBe",
    "outputId": "e1ab4496-c615-4e45-dfe6-e480a8e9ef31"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1166693308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dimension of the embedding vector \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_1' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the embedding vector \",len(embedding_1))\n",
    "len(embedding_1)==len(embedding_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SRtdZdjyrXE"
   },
   "source": [
    "* The embedding model provides a fixed-length vector for any number of chunks.  \n",
    "* This is necessary because we want to compare them for similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiKCOv4X0d7B"
   },
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1758461842861,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "NWOqhGMV0kZ9"
   },
   "outputs": [],
   "source": [
    "out_dir = 'apple_db'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "  os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "error",
     "timestamp": 1758461843015,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "8g-D3URW0iEO",
    "outputId": "f1430911-6868-4403-e003-f96189fa9456"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Chroma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-277725861.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vectorstore = Chroma.from_documents(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdocument_chunks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0membedding_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Chroma' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    document_chunks,\n",
    "    embedding_model,\n",
    "    persist_directory=out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "error",
     "timestamp": 1758461843185,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "SuK6hsbaGfqH",
    "outputId": "903ae82b-d305-4b77-ae97-f93fe9a6ee8e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Chroma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2756559696.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Chroma' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma(persist_directory=out_dir,embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1758461843394,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "GdZON_Uj1EeS",
    "outputId": "3a216f6e-f2c9-4965-d851-2b6b85219a8e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1081949635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "error",
     "timestamp": 1758461843578,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "P9HgsipF1I4H",
    "outputId": "7e451a18-8a6f-4d3c-9c55-d653673a7853"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3724743422.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Apple Steve Jobs iPhone \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"Apple Steve Jobs iPhone \",k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt3hqoXYzGoy"
   },
   "source": [
    "* From the retrieved chunks, we observe that all the chunks are related to the key terms [ 'Apple', 'Steve Jobs', 'iPhone' ]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEa5sKc41T1z"
   },
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "error",
     "timestamp": 1758461844120,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "zO5kmp381VsX",
    "outputId": "126e7115-b25e-4a6c-b511-2de8d9e0665c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1630620739.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m retriever = vectorstore.as_retriever(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msearch_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msearch_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "error",
     "timestamp": 1758461844285,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "bnKuqfWB1gBx",
    "outputId": "06cf7d95-c930-4bb2-c20c-48156c0d7be0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3586710401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrel_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How does does Apple develop and ship products that requires good coordination between the teams?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrel_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "rel_docs = retriever.get_relevant_documents(\"How does does Apple develop and ship products that requires good coordination between the teams?\")\n",
    "rel_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkYpfpUAzbqK"
   },
   "source": [
    "- We can observe that the two relevant chunks contain the answer to the query.  \n",
    "- If we increase the **`k`** value, there is a chance that we might find the answer in even more chunks.  \n",
    "- This is a hyperparameter that we need to tune to get the best context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imCgFJyq2SA6"
   },
   "source": [
    "# Defining the Response Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVdPdgVL9fhk"
   },
   "source": [
    "## Downloading and Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1758461844912,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "Cp5KZXxg9fhk"
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "error",
     "timestamp": 1758461845092,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "arILxg3j9fhl",
    "outputId": "0ed54e59-fe4f-40c5-e5ee-1004c3d2a9c6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_hub_download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-874167749.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_path = hf_hub_download(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_basename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_hub_download' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path,\n",
    "    filename=model_basename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "error",
     "timestamp": 1758461845159,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "46dB9ZqQ9fhl",
    "outputId": "9fc099ff-8599-451c-f8ab-ced0e286326f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Llama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-455531028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#uncomment the below snippet of code if the runtime is connected to GPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m llm = Llama(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_ctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_gpu_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Llama' is not defined"
     ]
    }
   ],
   "source": [
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=2300,\n",
    "    n_gpu_layers=38,\n",
    "    n_batch=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1758461845294,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "9FjKutIA9fhl"
   },
   "outputs": [],
   "source": [
    "llm = Llama(\n",
    "  model_path=model_path,\n",
    "   n_ctx=1024,\n",
    "  n_cores=-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "error",
     "timestamp": 1758461845449,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "JGuUFLSXvOSt",
    "outputId": "6e0c1982-614c-47e4-a111-125e3d5319aa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-176652517.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How does does Apple develop and ship products that requires good coordination between the teams?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "llm(\"How does does Apple develop and ship products that requires good coordination between the teams?\")['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnasHS43vaBD"
   },
   "source": [
    "- The response seems generic and appears to be derived from another article. Let's provide our own context and align the response with our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vw8qcwq66B0C"
   },
   "source": [
    "## System and User Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wRkZYtO6B0D"
   },
   "source": [
    "Prompts guide the model to generate accurate responses. Here, we define two parts:\n",
    "\n",
    "    1. The system message describing the assistant's role.\n",
    "    2. A user message template including context and the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1758461846171,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "Dyl60SEs6B0D"
   },
   "outputs": [],
   "source": [
    "qna_system_message = \"\"\"\n",
    "You are an assistant whose work is to review the report and provide the appropriate answers from the context.\n",
    "User input will have the context required by you to answer user questions.\n",
    "This context will begin with the token: ###Context.\n",
    "The context contains references to specific portions of a document relevant to the user query.\n",
    "\n",
    "User questions will begin with the token: ###Question.\n",
    "\n",
    "Please answer only using the context provided in the input. Do not mention anything about the context in your final answer.\n",
    "\n",
    "If the answer is not found in the context, respond \"I don't know\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1758461846309,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "XW38rWoNjJkQ"
   },
   "outputs": [],
   "source": [
    "qna_user_message_template = \"\"\"\n",
    "###Context\n",
    "Here are some documents that are relevant to the question mentioned below.\n",
    "{context}\n",
    "\n",
    "###Question\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkIteX4m6mny"
   },
   "source": [
    "## Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1758461846668,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "J-SfCZqC6B0E"
   },
   "outputs": [],
   "source": [
    "def generate_rag_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
    "    global qna_system_message,qna_user_message_template\n",
    "    # Retrieve relevant document chunks\n",
    "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=k)\n",
    "    context_list = [d.page_content for d in relevant_document_chunks]\n",
    "\n",
    "    # Combine document chunks into a single context\n",
    "    context_for_query = \". \".join(context_list)\n",
    "\n",
    "    user_message = qna_user_message_template.replace('{context}', context_for_query)\n",
    "    user_message = user_message.replace('{question}', user_input)\n",
    "\n",
    "    prompt = qna_system_message + '\\n' + user_message\n",
    "\n",
    "    # Generate the response\n",
    "    try:\n",
    "        response = llm(\n",
    "                  prompt=prompt,\n",
    "                  max_tokens=max_tokens,\n",
    "                  temperature=temperature,\n",
    "                  top_p=top_p,\n",
    "                  top_k=top_k\n",
    "                  )\n",
    "\n",
    "        # Extract and print the model's response\n",
    "        response = response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffP1SRYbPQHN"
   },
   "source": [
    "# Question Answering using RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjajBEj06B0E"
   },
   "source": [
    "### Query 1: Who are the authors of this article and who published this article ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "error",
     "timestamp": 1758461847220,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "Gt4TAQNa6B0E",
    "outputId": "f41ff635-e8ce-4ceb-d595-28fb04a2cbcf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2495549864.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who are the authors of this article and who published this article ?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_rag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-141734326.py\u001b[0m in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input, k, max_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mqna_system_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqna_user_message_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve relevant document chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrelevant_document_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_document_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "user_input = \"Who are the authors of this article and who published this article ?\"\n",
    "print(generate_rag_response(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYAgvE7700Gx"
   },
   "source": [
    "- The answer is clear, concise, and focused, without any unnecessary information.  \n",
    "\n",
    "- For queries like this, we expect a response of this nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDw8zXuq6B0F"
   },
   "source": [
    "### Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "error",
     "timestamp": 1758461848121,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "i92cv0dQ6B0F",
    "outputId": "ad839c18-da44-4080-f2a6-921af3e8d8ac"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2181589615.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_rag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-141734326.py\u001b[0m in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input, k, max_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mqna_system_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqna_user_message_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve relevant document chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrelevant_document_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_document_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
    "generate_rag_response(user_input_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe-GwPNs1XDC"
   },
   "source": [
    "- The response contains only two leadership characteristics, but they are well explained.  \n",
    "- Perhaps if we increase the **`max_tokens`**, we might get the third characteristic as well (assuming it is in the document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TggYyQPL6B0G"
   },
   "source": [
    "### Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1758461848326,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "Ed6x6LGb6B0G",
    "outputId": "a69e9eca-1b18-4bd0-f7ab-1ad0bc1466f7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-516344802.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_rag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-141734326.py\u001b[0m in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input, k, max_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mqna_system_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqna_user_message_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve relevant document chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrelevant_document_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_document_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
    "generate_rag_response(user_input_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSQzbaha1xvJ"
   },
   "source": [
    "- If we look at the system prompt, we explicitly mentioned that the query should not be answered if it cannot be derived from the context.  \n",
    "\n",
    "- As expected, the model has done its job well. It has eliminated hallucination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7TYrqycEITB"
   },
   "source": [
    "## Fine-tuning Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Tt270LOmj3t"
   },
   "source": [
    "### Query 1: Who are the authors of this article and who published this article ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "error",
     "timestamp": 1758461849076,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "qqdrbBN1mj3t",
    "outputId": "7bb7f205-1cd9-4565-d479-9f3322dea8b2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4037026274.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who are the authors of this article and who published this article ?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_rag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-141734326.py\u001b[0m in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input, k, max_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mqna_system_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqna_user_message_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve relevant document chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrelevant_document_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_document_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "user_input = \"Who are the authors of this article and who published this article ?\"\n",
    "generate_rag_response(user_input, max_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ-j__WeUx2Z"
   },
   "source": [
    "- Even if the **`max_tokens`** is set to 100, the model still didn't generate that many, as the query could be answered with a limited number of tokens.  \n",
    "\n",
    "- One of the reasons could be that the temperature is set to 0, making the model more deterministic and less creative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2oW34Ikmj3u"
   },
   "source": [
    "### Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "error",
     "timestamp": 1758461849605,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "3QqXzEjqmj3u",
    "outputId": "7ad90d4c-f46f-4a49-edc6-100edd9bf75d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1803789853.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_rag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-141734326.py\u001b[0m in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input, k, max_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mqna_system_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqna_user_message_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve relevant document chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrelevant_document_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_document_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
    "generate_rag_response(user_input_2, temperature=0.1, max_tokens=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkUfmKNsWKbD"
   },
   "source": [
    "- If we compare it to the previous case, after increasing the **`max_tokens`**, we got the third characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgwGYH8rmj3u"
   },
   "source": [
    "### Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "error",
     "timestamp": 1758461850121,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "bFrYiZnjmj3v",
    "outputId": "c71508ce-5c64-44d2-9e00-720443c60010"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1663229615.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_rag_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-141734326.py\u001b[0m in \u001b[0;36mgenerate_rag_response\u001b[0;34m(user_input, k, max_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mqna_system_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqna_user_message_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve relevant document chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrelevant_document_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcontext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_document_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
    "generate_rag_response(user_input_3, top_p=0.98, top_k=20, max_tokens=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yRXlorfXayK"
   },
   "source": [
    "- Since the context provided doesn't help with the query, the model has responded correctly based on the prompt design.  \n",
    "\n",
    "- However, there is a chance that it might not be present in the top **`k`** context. Therefore, it is better to experiment with higher values of **`k`** and check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyQrTipNfuBN"
   },
   "source": [
    "# Output Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbXMSxqa-65E"
   },
   "source": [
    "Let us now use the LLM-as-a-judge method to check the quality of the RAG system on two parameters - retrieval and generation. We illustrate this evaluation based on the answeres generated to the question from the previous section.\n",
    "\n",
    "- We are using the same Mistral model for evaluation, so basically here the llm is rating itself on how well he has performed in the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuNYGRDE4HpJ"
   },
   "source": [
    "### Defining the Evaluation Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1758461853222,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "2dDxkZdyKSnh"
   },
   "outputs": [],
   "source": [
    "groundedness_rater_system_message = \"\"\"\n",
    "You are tasked with rating AI generated answers to questions posed by users.\n",
    "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
    "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
    "\n",
    "Evaluation criteria:\n",
    "The task is to judge the extent to which the metric is followed by the answer.\n",
    "1 - The metric is not followed at all\n",
    "2 - The metric is followed only to a limited extent\n",
    "3 - The metric is followed to a good extent\n",
    "4 - The metric is followed mostly\n",
    "5 - The metric is followed completely\n",
    "\n",
    "Metric:\n",
    "The answer should be derived only from the information presented in the context\n",
    "\n",
    "Instructions:\n",
    "1. First write down the steps that are needed to evaluate the answer as per the metric.\n",
    "2. Give a step-by-step explanation if the answer adheres to the metric considering the question and context as the input.\n",
    "3. Next, evaluate the extent to which the metric is followed.\n",
    "4. Use the previous information to rate the answer using the evaluaton criteria and assign a score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1758461853651,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "NIosu2Wk7OVs"
   },
   "outputs": [],
   "source": [
    "relevance_rater_system_message = \"\"\"\n",
    "You are tasked with rating AI generated answers to questions posed by users.\n",
    "You will be presented a question, context used by the AI system to generate the answer and an AI generated answer to the question.\n",
    "In the input, the question will begin with ###Question, the context will begin with ###Context while the AI generated answer will begin with ###Answer.\n",
    "\n",
    "Evaluation criteria:\n",
    "The task is to judge the extent to which the metric is followed by the answer.\n",
    "1 - The metric is not followed at all\n",
    "2 - The metric is followed only to a limited extent\n",
    "3 - The metric is followed to a good extent\n",
    "4 - The metric is followed mostly\n",
    "5 - The metric is followed completely\n",
    "\n",
    "Metric:\n",
    "Relevance measures how well the answer addresses the main aspects of the question, based on the context.\n",
    "Consider whether all and only the important aspects are contained in the answer when evaluating relevance.\n",
    "\n",
    "Instructions:\n",
    "1. First write down the steps that are needed to evaluate the context as per the metric.\n",
    "2. Give a step-by-step explanation if the context adheres to the metric considering the question as the input.\n",
    "3. Next, evaluate the extent to which the metric is followed.\n",
    "4. Use the previous information to rate the context using the evaluaton criteria and assign a score.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1758461853849,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "7boMupgh_Gux"
   },
   "outputs": [],
   "source": [
    "user_message_template = \"\"\"\n",
    "###Question\n",
    "{question}\n",
    "\n",
    "###Context\n",
    "{context}\n",
    "\n",
    "###Answer\n",
    "{answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8XUDmew4Mzn"
   },
   "source": [
    "### Defining the Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1758461854255,
     "user": {
      "displayName": "Mr. Ashwani Balyan (SU Training Delivery Manager)",
      "userId": "10495710902595717956"
     },
     "user_tz": -330
    },
    "id": "q9UVEOZbXYlh"
   },
   "outputs": [],
   "source": [
    "def generate_ground_relevance_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
    "    global qna_system_message,qna_user_message_template\n",
    "    # Retrieve relevant document chunks\n",
    "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=3)\n",
    "    context_list = [d.page_content for d in relevant_document_chunks]\n",
    "    context_for_query = \". \".join(context_list)\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt = f\"\"\"[INST]{qna_system_message}\\n\n",
    "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=user_input)}\n",
    "                [/INST]\"\"\"\n",
    "\n",
    "    response = llm(\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            stop=['INST'],\n",
    "            )\n",
    "\n",
    "    answer =  response[\"choices\"][0][\"text\"]\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    groundedness_prompt = f\"\"\"[INST]{groundedness_rater_system_message}\\n\n",
    "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
    "                [/INST]\"\"\"\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    relevance_prompt = f\"\"\"[INST]{relevance_rater_system_message}\\n\n",
    "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
    "                [/INST]\"\"\"\n",
    "\n",
    "    response_1 = llm(\n",
    "            prompt=groundedness_prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            stop=['INST'],\n",
    "            )\n",
    "\n",
    "    response_2 = llm(\n",
    "            prompt=relevance_prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            stop=['INST'],\n",
    "            )\n",
    "\n",
    "    return response_1['choices'][0]['text'],response_2['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Yr8azRRmxsg"
   },
   "source": [
    "### Query 1: Who are the authors of this article and who published this article ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Who are the authors of this article and who published this article ?\"\n",
    "ground,rel = generate_ground_relevance_response(user_input,max_tokens=350)\n",
    "\n",
    "print(ground,end=\"\\n\\n\")\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgJI4DOdGHx0"
   },
   "source": [
    "- It got a perfect score because the response is both grounded in the context and relevant to the query.  \n",
    "- This means that both the retrieval and augmentation parts are good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDH6Va3Bmxsh"
   },
   "source": [
    "### Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
    "ground,rel = generate_ground_relevance_response(user_input_2,max_tokens=500)\n",
    "\n",
    "print(ground,end=\"\\n\\n\")\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpcn0QLOHLYW"
   },
   "source": [
    "- The groundedness score is 5 since the response is derived solely from the context.  \n",
    "\n",
    "- Regarding relevance, the score is 4 (the metric is mostly followed). However, it is not very clear why this rating was given.  \n",
    "\n",
    "- One solution is to modify the relevance prompt to instruct the model to provide reasons for any point deductions or increase the max_tokens (assuming the output has been truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6xAHrl9mxsh"
   },
   "source": [
    "### Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
    "ground,rel = generate_ground_relevance_response(user_input_3,max_tokens=500)\n",
    "\n",
    "print(ground,end=\"\\n\\n\")\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duJHMNwbIAVl"
   },
   "source": [
    "- For relevance, the response includes both the score and the reason for the point deduction.  \n",
    "\n",
    "- For groundedness, it is unclear why one point was deducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i8pILGhmWzf"
   },
   "source": [
    "<section class=\"rag-conclusion\" style=\"font-family:system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; line-height:1.6;\">\n",
    "  <h2 style=\"margin:0 0 .5rem;\">Conclusion</h2>\n",
    "  <p style=\"margin:.25rem 0 1rem;\">\n",
    "    For reliable, concise, and contextually accurate RAG outputs, tune retrieval and generation together—favoring groundedness over verbosity.\n",
    "  </p>\n",
    "  <ul style=\"margin:.5rem 0 1rem 1.25rem;\">\n",
    "    <li><strong>Indexing:</strong> Larger PDFs increase vectorization time; batch and cache embeddings.</li>\n",
    "    <li><strong>Retrieval depth (<code>k</code>):</strong> Raise when answers span sections; lower for focused queries to reduce noise.</li>\n",
    "    <li><strong>Chunking:</strong> Use <code>chunk_overlap</code> to preserve continuity across boundaries without inflating recall.</li>\n",
    "    <li><strong>Generation limits:</strong> Set <code>max_tokens</code> to match query complexity; prompt structure and <code>temperature=0</code> keep simple answers brief.</li>\n",
    "    <li><strong>Prompt &amp; creativity:</strong> Iterate prompts and adjust temperature to balance precision with flexibility.</li>\n",
    "    <li><strong>Evaluation:</strong> Prioritize groundedness and relevance; measure with task-specific checks.</li>\n",
    "    <li><strong>Feedback loop:</strong> Continuously refine parameters per use case using logged queries and outcomes.</li>\n",
    "  </ul>\n",
    "  <p style=\"margin:0;\">\n",
    "    Start conservative (low <code>k</code>, moderate overlap, strict prompts), evaluate groundedness, then incrementally expand scope (tokens, <code>k</code>, overlap) only when evidence shows improved answer coverage.\n",
    "  </p>\n",
    "</section>\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1t_8uaRxmkL7BOPQSkg0suATi-6P8WjPv",
     "timestamp": 1758454446265
    }
   ]
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
